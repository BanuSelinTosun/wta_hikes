{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import enchant\n",
    "from pymongo import MongoClient\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "connection = MongoClient()\n",
    "db = connection.wta\n",
    "\n",
    "def mongo2PandasClean(mongodb, drop_id=True):\n",
    "    df = pd.DataFrame(list(mongodb.find()))\n",
    "    if drop_id:\n",
    "        del df['_id']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = mongo2PandasClean(db.trainingTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pine Ridge Trail to Sykes Hot Springs</td>\n",
       "      <td>5</td>\n",
       "      <td>Not much to see but the hot springs are worth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pine Ridge Trail to Sykes Hot Springs</td>\n",
       "      <td>3</td>\n",
       "      <td>The proximity to San Francisco is super conven...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pine Ridge Trail to Sykes Hot Springs</td>\n",
       "      <td>1</td>\n",
       "      <td>We hiked in and back in one day.  A little ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pine Ridge Trail to Sykes Hot Springs</td>\n",
       "      <td>3</td>\n",
       "      <td>This hike is very strenuous.  The first 4 mile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pine Ridge Trail to Sykes Hot Springs</td>\n",
       "      <td>5</td>\n",
       "      <td>Challenging, beautiful and worth it! go mid we...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Name Rating  \\\n",
       "0  Pine Ridge Trail to Sykes Hot Springs      5   \n",
       "1  Pine Ridge Trail to Sykes Hot Springs      3   \n",
       "2  Pine Ridge Trail to Sykes Hot Springs      1   \n",
       "3  Pine Ridge Trail to Sykes Hot Springs      3   \n",
       "4  Pine Ridge Trail to Sykes Hot Springs      5   \n",
       "\n",
       "                                                Text  \n",
       "0  Not much to see but the hot springs are worth ...  \n",
       "1  The proximity to San Francisco is super conven...  \n",
       "2  We hiked in and back in one day.  A little ove...  \n",
       "3  This hike is very strenuous.  The first 4 mile...  \n",
       "4  Challenging, beautiful and worth it! go mid we...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    369\n",
       "4    127\n",
       "3     20\n",
       "1      4\n",
       "2      3\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So imbalanced!  So for this I'm going to use scikit-learn's imbalance package.\n",
    "\n",
    "https://github.com/scikit-learn-contrib/imbalanced-learn/blob/master/examples/over-sampling/plot_random_over_sampling.py\n",
    "\n",
    "In order to use this example, I have to complete the following steps:\n",
    "\n",
    "    1) Check that all of my entries are in English and remove those that aren't\n",
    "    \n",
    "    2) Vectorize the text into featues and apply PCA\n",
    "    \n",
    "    3) Apply oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop nonEnglish rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = enchant.Dict(\"en_US\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dropNonEnglish(row):\n",
    "    eng = 0\n",
    "    words = 0\n",
    "    for word in row.split():\n",
    "        words += 1\n",
    "        if d.check(word):\n",
    "            eng += 1\n",
    "    return eng/words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(523, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['Text'].map(dropNonEnglish) > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(487, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['Positive'] = [1 if int(r) > 3 else 0 for r in train_df['Rating']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', max_df=0.5, max_features=100).fit(train_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = tfidf.transform(train_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_df['Positive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = features.toarray()\n",
    "y = train_df['Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "# Fit and transform x to visualise inside a 2D feature space\n",
    "X_vis = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "almost_black = '#262626'\n",
    "palette = sns.color_palette()\n",
    "# Apply the random over-sampling\n",
    "ros = RandomOverSampler()\n",
    "X_resampled, y_resampled = ros.fit_sample(X, y)\n",
    "X_res_vis = pca.transform(X_resampled)\n",
    "\n",
    "# Two subplots, unpack the axes array immediately\n",
    "f, (ax1, ax2) = plt.subplots(1, 2)\n",
    "\n",
    "ax1.scatter(X_vis[0][y == 0], X_vis[1][y == 0], label=\"Class #0\", alpha=0.5,\n",
    "            edgecolor=almost_black, facecolor=palette[0], linewidth=0.15)\n",
    "ax1.scatter(X_vis[1][y == 1], X_vis[1][y == 1], label=\"Class #1\", alpha=0.5,\n",
    "            edgecolor=almost_black, facecolor=palette[2], linewidth=0.15)\n",
    "ax1.set_title('Original set')\n",
    "\n",
    "ax2.scatter(X_res_vis[y_resampled == 0, 0], X_res_vis[y_resampled == 0, 1],\n",
    "            label=\"Class #0\", alpha=.5, edgecolor=almost_black,\n",
    "            facecolor=palette[0], linewidth=0.15)\n",
    "ax2.scatter(X_res_vis[y_resampled == 1, 0], X_res_vis[y_resampled == 1, 1],\n",
    "            label=\"Class #1\", alpha=.5, edgecolor=almost_black,\n",
    "            facecolor=palette[2], linewidth=0.15)\n",
    "ax2.set_title('Random over-sampling')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = train_df[train_df['Positive'] == 0].index.tolist()\n",
    "num_samples = len(train_df[train_df['Positive']==1]) - len(train_df[train_df['Positive']==0]) \n",
    "ix = np.random.choice(sample, size=num_samples, replace=True)\n",
    "train_df_equal = train_df.append(train_df.ix[ix])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    466\n",
       "0    466\n",
       "Name: Positive, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_equal['Positive'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = train_df['Text']\n",
    "y = train_df['Positive']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analyzer\n",
    "\n",
    "https://github.com/zipfian/DSCI6004-instructor/blob/master/week5/5_1_SentimentMultinomialBayes/Text%20classification%20and%20Naive%20Bayes.pdf\n",
    "\n",
    "http://www.nltk.org/book/ch06.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MNB classifier](MNB.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re, math, collections, itertools, os\n",
    "import nltk, nltk.classify.util, nltk.metrics.scores\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "from nltk.probability import FreqDist, ConditionalFreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def trainModel(df):\n",
    "    pos = df['Text'][df['Positive']==1]\n",
    "    neg = df['Text'][df['Positive']==0]\n",
    "    posWords = []\n",
    "    negWords = []\n",
    "\n",
    "    for row in pos:\n",
    "        words = row.lower().split()\n",
    "        words = [dict([(word.strip(string.punctuation), True) for word in words]), 'pos']\n",
    "        posWords.append(words)\n",
    "    for row in neg:\n",
    "        words = row.lower().split()\n",
    "        words = [dict([(word.strip(string.punctuation), True) for word in words]), 'neg']\n",
    "        posWords.append(words)\n",
    "\n",
    "    posCutoff = int(math.floor(len(posWords)*3/4))\n",
    "    negCutoff = int(math.floor(len(negWords)*3/4))\n",
    "    trainFeatures = posWords[:posCutoff] + negWords[:negCutoff]\n",
    "    testFeatures = posWords[posCutoff:] + negWords[negCutoff:]\n",
    "\n",
    "    classifier = NaiveBayesClassifier.train(trainFeatures)\n",
    "\n",
    "    print(nltk.classify.accuracy(classifier, testFeatures))\n",
    "    print classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Most Informative Features\n",
      "                   paper = True              neg : pos    =     39.2 : 1.0\n",
      "                    test = True              neg : pos    =     33.9 : 1.0\n",
      "                location = True              neg : pos    =     27.5 : 1.0\n",
      "                  groups = True              neg : pos    =     24.6 : 1.0\n",
      "               depending = True              neg : pos    =     24.6 : 1.0\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "trainModel(train_df_equal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9568788501026694"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
